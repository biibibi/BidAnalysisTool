#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šæ¨¡æ€æ–‡æ¡£åˆ†æAPIæ¨¡å—
====================

æœ¬æ¨¡å—æä¾›å°†åŒ…å«å›¾ç‰‡å’Œæ–‡å­—çš„docxæ–‡æ¡£ç›´æ¥ä½œä¸ºå¤§æ¨¡å‹APIè¾“å…¥çš„åŠŸèƒ½ã€‚
æ ¹æ®æµç¨‹.txtçš„è¦æ±‚ï¼Œå®ç°æ–‡æ¡£å†…å®¹æå–ã€å›¾ç‰‡ç¼–ç å’Œå¤šæ¨¡æ€promptæ„å»ºã€‚

ä¸»è¦åŠŸèƒ½ï¼š
    1. ä»docxæ–‡æ¡£ä¸­æå–æ‰€æœ‰æ–‡å­—å†…å®¹å’Œå›¾ç‰‡
    2. å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64ç¼–ç 
    3. æ„å»ºå¤šæ¨¡æ€promptå‘é€ç»™å¤§æ¨¡å‹
    4. æ”¯æŒQwen-VL-Maxç­‰å¤šæ¨¡æ€æ¨¡å‹

åˆ›å»ºæ—¶é—´ï¼š2025å¹´9æœˆ28æ—¥
"""

import os
import base64
import tempfile
from typing import Dict, List, Any, Optional, Union
from pathlib import Path
from docx import Document
from docx.shared import Inches
from PIL import Image
from io import BytesIO
import json
import logging
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(Path(__file__).resolve().parent / ".env", override=False)

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


class MultimodalDocumentAnalyzer:
    """
    å¤šæ¨¡æ€æ–‡æ¡£åˆ†æå™¨
    ================
    
    å°†åŒ…å«å›¾ç‰‡å’Œæ–‡å­—çš„Wordæ–‡æ¡£ç›´æ¥è½¬æ¢ä¸ºå¤šæ¨¡æ€APIè¾“å…¥ï¼Œ
    å®ç°çœŸæ­£æ„ä¹‰ä¸Šçš„"è®©AIç†è§£å®Œæ•´çš„Wordæ–‡æ¡£"ã€‚
    
    ä¸»è¦æ–¹æ³•ï¼š
        - extract_text_and_images(): æå–æ–‡æ¡£å†…å®¹
        - analyze_document(): å¤šæ¨¡æ€æ–‡æ¡£åˆ†æ
        - _build_multimodal_prompt(): æ„å»ºå¤šæ¨¡æ€æç¤ºè¯
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–å¤šæ¨¡æ€æ–‡æ¡£åˆ†æå™¨
        
        é…ç½®æ”¯æŒçš„å¤§æ¨¡å‹æä¾›å•†å’ŒAPIå‚æ•°
        """
        self.provider = os.getenv("LLM_PROVIDER", "qwen").lower()
        self._init_clients()
        
    def _init_clients(self):
        """åˆå§‹åŒ–ä¸åŒæä¾›å•†çš„å®¢æˆ·ç«¯"""
        # åˆå§‹åŒ–Qwenå®¢æˆ·ç«¯
        self.qwen_client = None
        qwen_key = os.getenv("DASHSCOPE_API_KEY")
        if qwen_key:
            self.qwen_client = OpenAI(
                api_key=qwen_key,
                base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
            )
        
        # åˆå§‹åŒ–è±†åŒ…å®¢æˆ·ç«¯
        self.doubao_client = None
        ark_key = os.getenv("ARK_API_KEY")
        if ark_key:
            self.doubao_client = OpenAI(
                api_key=ark_key,
                base_url=os.getenv("ARK_BASE_URL", "https://ark.cn-beijing.volces.com/api/v3")
            )

    def extract_text_and_images(self, docx_path: Union[str, Path]) -> Dict[str, Any]:
        """
        ä»docxæ–‡æ¡£ä¸­æå–æ–‡å­—å†…å®¹å’Œå›¾ç‰‡
        ==============================
        
        æŒ‰ç…§æµç¨‹.txtçš„è¦æ±‚æå–æ–‡æ¡£ä¸­çš„æ‰€æœ‰æ–‡å­—å’Œå›¾ç‰‡å†…å®¹ã€‚
        
        Args:
            docx_path: Wordæ–‡æ¡£è·¯å¾„
            
        Returns:
            Dict: åŒ…å«æ–‡å­—å†…å®¹å’Œå›¾ç‰‡base64ç¼–ç çš„å­—å…¸
                - text_content: æ–‡æ¡£çš„å®Œæ•´æ–‡å­—å†…å®¹
                - images: å›¾ç‰‡base64ç¼–ç åˆ—è¡¨
                - image_count: å›¾ç‰‡æ•°é‡
                - success: æ˜¯å¦æˆåŠŸæå–
                - error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        """
        try:
            docx_path = Path(docx_path)
            if not docx_path.exists():
                return {
                    "success": False,
                    "error": f"æ–‡æ¡£ä¸å­˜åœ¨ï¼š{docx_path}",
                    "text_content": "",
                    "images": [],
                    "image_count": 0
                }
            
            # åŠ è½½æ–‡æ¡£
            doc = Document(docx_path)
            
            # 1. æå–æ‰€æœ‰æ–‡å­—å†…å®¹
            text_lines = []
            
            # æå–æ®µè½æ–‡å­—
            for para in doc.paragraphs:
                if para.text.strip():
                    text_lines.append(para.text.strip())
            
            # æå–è¡¨æ ¼æ–‡å­—
            for table in doc.tables:
                for row in table.rows:
                    row_texts = []
                    for cell in row.cells:
                        if cell.text.strip():
                            row_texts.append(cell.text.strip())
                    if row_texts:
                        text_lines.append(" | ".join(row_texts))
            
            full_text = "\n".join(text_lines)
            
            # 2. æå–å’Œç¼–ç æ‰€æœ‰å›¾ç‰‡
            images_base64 = []
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•ä¿å­˜å›¾ç‰‡
            with tempfile.TemporaryDirectory() as temp_dir:
                temp_path = Path(temp_dir)
                
                # éå†æ–‡æ¡£ä¸­çš„å›¾ç‰‡å…³ç³»
                image_counter = 0
                for rel in doc.part.rels.values():
                    if "image" in rel.reltype:
                        try:
                            # è·å–å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®
                            image_data = rel.target_part.blob
                            
                            # ä¿å­˜ä¸´æ—¶å›¾ç‰‡æ–‡ä»¶ç”¨äºéªŒè¯æ ¼å¼
                            img_temp_path = temp_path / f"temp_image_{image_counter}.png"
                            with open(img_temp_path, 'wb') as f:
                                f.write(image_data)
                            
                            # ä½¿ç”¨PILéªŒè¯å’Œæ ‡å‡†åŒ–å›¾ç‰‡æ ¼å¼
                            with Image.open(BytesIO(image_data)) as img:
                                # è½¬æ¢ä¸ºRGBæ¨¡å¼ï¼ˆç¡®ä¿å…¼å®¹æ€§ï¼‰
                                if img.mode in ('RGBA', 'LA', 'P'):
                                    img = img.convert('RGB')
                                
                                # é‡æ–°ä¿å­˜ä¸ºæ ‡å‡†æ ¼å¼
                                img_buffer = BytesIO()
                                img.save(img_buffer, format='JPEG', quality=85)
                                img_buffer.seek(0)
                                
                                # è½¬æ¢ä¸ºbase64
                                encoded_img = base64.b64encode(img_buffer.getvalue()).decode('utf-8')
                                images_base64.append(f"data:image/jpeg;base64,{encoded_img}")
                                image_counter += 1
                                
                        except Exception as e:
                            logger.warning(f"å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™ï¼š{str(e)}")
                            continue
            
            logger.info(f"æˆåŠŸæå–æ–‡æ¡£å†…å®¹ï¼šæ–‡å­— {len(full_text)} å­—ç¬¦ï¼Œå›¾ç‰‡ {len(images_base64)} å¼ ")
            
            return {
                "success": True,
                "text_content": full_text,
                "images": images_base64,
                "image_count": len(images_base64),
                "error": None
            }
            
        except Exception as e:
            error_msg = f"æå–æ–‡æ¡£å†…å®¹å¤±è´¥ï¼š{str(e)}"
            logger.error(error_msg)
            return {
                "success": False,
                "error": error_msg,
                "text_content": "",
                "images": [],
                "image_count": 0
            }

    def analyze_document(self, 
                        docx_path: Union[str, Path], 
                        analysis_prompt: str = None,
                        provider: str = None) -> Dict[str, Any]:
        """
        å¤šæ¨¡æ€æ–‡æ¡£åˆ†æ
        ==============
        
        æŒ‰ç…§æµç¨‹.txtçš„å®Œæ•´æµç¨‹ï¼Œå°†Wordæ–‡æ¡£è½¬æ¢ä¸ºå¤šæ¨¡æ€è¾“å…¥å¹¶è°ƒç”¨å¤§æ¨¡å‹åˆ†æã€‚
        
        Args:
            docx_path: Wordæ–‡æ¡£è·¯å¾„
            analysis_prompt: è‡ªå®šä¹‰åˆ†ææç¤ºè¯ï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤çš„æˆæƒå§”æ‰˜ä¹¦åˆ†æ
            provider: æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹æä¾›å•†ï¼Œæ”¯æŒ 'qwen' æˆ– 'doubao'
            
        Returns:
            Dict: åˆ†æç»“æœ
                - success: æ˜¯å¦æˆåŠŸ
                - result: å¤§æ¨¡å‹åˆ†æç»“æœ
                - text_content: æå–çš„æ–‡å­—å†…å®¹
                - image_count: å›¾ç‰‡æ•°é‡
                - error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        """
        try:
            # 1. æå–æ–‡æ¡£å†…å®¹
            logger.info(f"å¼€å§‹åˆ†ææ–‡æ¡£ï¼š{docx_path}")
            extract_result = self.extract_text_and_images(docx_path)
            
            if not extract_result["success"]:
                return extract_result
            
            text_content = extract_result["text_content"]
            images = extract_result["images"]
            
            if not text_content and not images:
                return {
                    "success": False,
                    "error": "æ–‡æ¡£ä¸­æ²¡æœ‰æ‰¾åˆ°æ–‡å­—å†…å®¹æˆ–å›¾ç‰‡",
                    "result": None,
                    "text_content": "",
                    "image_count": 0
                }
            
            # 2. æ„å»ºå¤šæ¨¡æ€prompt
            multimodal_messages = self._build_multimodal_prompt(
                text_content, images, analysis_prompt
            )
            
            # 3. è°ƒç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹API
            api_result = self._call_multimodal_api(multimodal_messages, provider)
            
            return {
                "success": api_result["success"],
                "result": api_result.get("result"),
                "text_content": text_content,
                "image_count": len(images),
                "error": api_result.get("error")
            }
            
        except Exception as e:
            error_msg = f"æ–‡æ¡£åˆ†æå¤±è´¥ï¼š{str(e)}"
            logger.error(error_msg)
            return {
                "success": False,
                "error": error_msg,
                "result": None,
                "text_content": "",
                "image_count": 0
            }

    def _build_multimodal_prompt(self, 
                                text_content: str, 
                                images: List[str], 
                                custom_prompt: str = None) -> List[Dict[str, Any]]:
        """
        æ„å»ºå¤šæ¨¡æ€æç¤ºè¯
        ================
        
        æŒ‰ç…§æµç¨‹.txtçš„æ ¼å¼è¦æ±‚æ„å»ºå¤šæ¨¡æ€promptã€‚
        
        Args:
            text_content: æ–‡æ¡£æ–‡å­—å†…å®¹
            images: å›¾ç‰‡base64ç¼–ç åˆ—è¡¨
            custom_prompt: è‡ªå®šä¹‰æç¤ºè¯
            
        Returns:
            List[Dict]: å¤šæ¨¡æ€æ¶ˆæ¯åˆ—è¡¨
        """
        # æ„å»ºæ¶ˆæ¯å†…å®¹åˆ—è¡¨
        content_parts = []
        
        # æ·»åŠ ä»»åŠ¡è¯´æ˜
        content_parts.append({
            "type": "text",
            "text": custom_prompt
        })
        
        # æ·»åŠ æ–‡å­—å†…å®¹
        if text_content:
            content_parts.append({
                "type": "text", 
                "text": f"ã€æ–‡æ¡£æ–‡å­—å†…å®¹ã€‘\n{text_content}"
            })
        
        # æ·»åŠ å›¾ç‰‡å†…å®¹
        if images:
            content_parts.append({
                "type": "text",
                "text": f"ã€æ–‡æ¡£åŒ…å«å›¾ç‰‡ã€‘\nä»¥ä¸‹æ˜¯æ–‡æ¡£ä¸­çš„ {len(images)} å¼ å›¾ç‰‡ï¼š"
            })
            
            for i, img_base64 in enumerate(images, 1):
                content_parts.append({
                    "type": "text",
                    "text": f"å›¾ç‰‡ {i}ï¼š"
                })
                content_parts.append({
                    "type": "image_url",
                    "image_url": {
                        "url": img_base64
                    }
                })
        
        # æ·»åŠ æœ€ç»ˆåˆ†æè¦æ±‚
        content_parts.append({
            "type": "text",
            "text": "\nè¯·ç»¼åˆæ–‡å­—å†…å®¹å’Œå›¾ç‰‡ä¿¡æ¯è¿›è¡Œå®Œæ•´åˆ†æï¼Œç¡®ä¿ä¿¡æ¯çš„ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§ã€‚"
        })
        
        return [
            {
                "role": "user",
                "content": content_parts
            }
        ]

    def _call_multimodal_api(self, 
                           messages: List[Dict[str, Any]], 
                           provider: str = None) -> Dict[str, Any]:
        """
        è°ƒç”¨å¤šæ¨¡æ€å¤§æ¨¡å‹API
        =================
        
        æ ¹æ®æŒ‡å®šçš„æä¾›å•†è°ƒç”¨ç›¸åº”çš„å¤šæ¨¡æ€APIã€‚
        
        Args:
            messages: å¤šæ¨¡æ€æ¶ˆæ¯åˆ—è¡¨
            provider: æŒ‡å®šçš„æä¾›å•†
            
        Returns:
            Dict: APIè°ƒç”¨ç»“æœ
        """
        provider = provider or self.provider
        
        try:
            if provider in ("qwen", "ali", "dashscope"):
                return self._call_qwen_vl_api(messages)
            elif provider in ("doubao", "ark", "volc"):
                return self._call_doubao_vision_api(messages)
            else:
                # é»˜è®¤ä½¿ç”¨Qwen
                return self._call_qwen_vl_api(messages)
                
        except Exception as e:
            return {
                "success": False,
                "error": f"APIè°ƒç”¨å¤±è´¥ï¼š{str(e)}",
                "result": None
            }

    def _call_qwen_vl_api(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è°ƒç”¨Qwen-VL-Max API"""
        if not self.qwen_client:
            return {
                "success": False,
                "error": "Qwenå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥DASHSCOPE_API_KEYç¯å¢ƒå˜é‡",
                "result": None
            }
        
        try:
            # ä½¿ç”¨qwen3-vl-plusæ¨¡å‹
            model = os.getenv("QWEN_VL_MODEL", "qwen3-vl-plus")
            
            response = self.qwen_client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.3,
                max_tokens=2000
            )
            
            result = response.choices[0].message.content
            
            logger.info(f"Qwen-VL APIè°ƒç”¨æˆåŠŸï¼Œè¿”å› {len(result)} å­—ç¬¦")
            
            return {
                "success": True,
                "result": result,
                "error": None
            }
            
        except Exception as e:
            error_msg = f"Qwen-VL APIè°ƒç”¨å¤±è´¥ï¼š{str(e)}"
            logger.error(error_msg)
            return {
                "success": False,
                "error": error_msg,
                "result": None
            }

    def _call_doubao_vision_api(self, messages: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è°ƒç”¨è±†åŒ…è§†è§‰API"""
        if not self.doubao_client:
            return {
                "success": False,
                "error": "è±†åŒ…å®¢æˆ·ç«¯æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥ARK_API_KEYç¯å¢ƒå˜é‡",
                "result": None
            }
        
        try:
            # ä½¿ç”¨è±†åŒ…è§†è§‰æ¨¡å‹
            model = os.getenv("DOUBAO_VISION_MODEL", "doubao-vision")
            
            response = self.doubao_client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=0.3,
                max_tokens=2000
            )
            
            result = response.choices[0].message.content
            
            logger.info(f"è±†åŒ…è§†è§‰APIè°ƒç”¨æˆåŠŸï¼Œè¿”å› {len(result)} å­—ç¬¦")
            
            return {
                "success": True,
                "result": result,
                "error": None
            }
            
        except Exception as e:
            error_msg = f"è±†åŒ…è§†è§‰APIè°ƒç”¨å¤±è´¥ï¼š{str(e)}"
            logger.error(error_msg)
            return {
                "success": False,
                "error": error_msg,
                "result": None
            }


# ä¾¿æ·å‡½æ•°
def analyze_document_with_multimodal(docx_path: Union[str, Path], 
                                   analysis_prompt: str = None,
                                   provider: str = None) -> Dict[str, Any]:
    """
    ä¾¿æ·çš„å¤šæ¨¡æ€æ–‡æ¡£åˆ†æå‡½æ•°
    ========================
    
    è¿™æ˜¯ä¸€ä¸ªå¿«é€Ÿä½¿ç”¨çš„å…¥å£å‡½æ•°ï¼ŒæŒ‰ç…§æµç¨‹.txtçš„è¦æ±‚å®ç°å®Œæ•´çš„å¤šæ¨¡æ€æ–‡æ¡£åˆ†æã€‚
    
    Args:
        docx_path: Wordæ–‡æ¡£è·¯å¾„
        analysis_prompt: è‡ªå®šä¹‰åˆ†ææç¤ºè¯
        provider: æŒ‡å®šæ¨¡å‹æä¾›å•† ('qwen' æˆ– 'doubao')
        
    Returns:
        Dict: åˆ†æç»“æœ
        
    ä½¿ç”¨ç¤ºä¾‹ï¼š
        # åˆ†ææˆæƒå§”æ‰˜ä¹¦
        result = analyze_document_with_multimodal("æˆæƒå§”æ‰˜ä¹¦.docx")
        
        # ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯
        custom_prompt = "è¯·åˆ†æè¿™ä¸ªæŠ•æ ‡æ–‡ä»¶çš„å®Œæ•´æ€§..."
        result = analyze_document_with_multimodal("æŠ•æ ‡æ–‡ä»¶.docx", custom_prompt)
        
        # æŒ‡å®šä½¿ç”¨è±†åŒ…æ¨¡å‹
        result = analyze_document_with_multimodal("æ–‡æ¡£.docx", provider="doubao")
    """
    analyzer = MultimodalDocumentAnalyzer()
    return analyzer.analyze_document(docx_path, analysis_prompt, provider)


def extract_document_content(docx_path: Union[str, Path]) -> Dict[str, Any]:
    """
    ä¾¿æ·çš„æ–‡æ¡£å†…å®¹æå–å‡½æ•°
    ======================
    
    åªæå–æ–‡æ¡£å†…å®¹è€Œä¸è°ƒç”¨AIåˆ†æã€‚
    
    Args:
        docx_path: Wordæ–‡æ¡£è·¯å¾„
        
    Returns:
        Dict: æå–ç»“æœï¼ŒåŒ…å«text_contentå’Œimages
    """
    analyzer = MultimodalDocumentAnalyzer()
    return analyzer.extract_text_and_images(docx_path)


# ä¸»å‡½æ•°ç¤ºä¾‹
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•ï¼špython multimodal_api.py <docxæ–‡ä»¶è·¯å¾„>")
        sys.exit(1)
    
    docx_file = sys.argv[1]
    
    print(f"å¼€å§‹åˆ†ææ–‡æ¡£ï¼š{docx_file}")
    print("=" * 50)
    
    # æ‰§è¡Œå¤šæ¨¡æ€åˆ†æ
    result = analyze_document_with_multimodal(docx_file)
    
    if result["success"]:
        print(f"âœ… åˆ†ææˆåŠŸï¼")
        print(f"ğŸ“ æ–‡å­—å†…å®¹é•¿åº¦ï¼š{len(result['text_content'])} å­—ç¬¦")
        print(f"ğŸ–¼ï¸  å›¾ç‰‡æ•°é‡ï¼š{result['image_count']} å¼ ")
        print("\nğŸ“Š åˆ†æç»“æœï¼š")
        print("-" * 30)
        print(result["result"])
    else:
        print(f"âŒ åˆ†æå¤±è´¥ï¼š{result['error']}")